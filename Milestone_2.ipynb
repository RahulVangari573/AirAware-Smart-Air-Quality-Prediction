{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AP8dbuz3Krx4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib, pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from prophet import Prophet\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the cleaned dataset\n",
        "data = pd.read_csv(\"/content/cleaned_air_quality (1).csv\")\n",
        "print(\"Loaded dataset:\", data.shape)\n",
        "print(\"Columns:\", list(data.columns))\n",
        "print(data.head())\n",
        "\n",
        "# We will predict PM2.5 levels per city\n",
        "target_col = \"PM2.5\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gemObRMcM2bo",
        "outputId": "22d4167c-d62e-40f4-f216-02b7dc4f669a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset: (7957, 11)\n",
            "Columns: ['City', 'Country', 'PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'O3', 'Temperature', 'Humidity', 'Wind Speed']\n",
            "             City   Country   PM2.5    PM10    NO2    SO2    CO      O3  \\\n",
            "0         Bangkok  Thailand   86.57   25.19  99.88  30.63  4.46   36.29   \n",
            "1        Istanbul    Turkey   50.63   97.39  48.14   8.71  3.40  144.16   \n",
            "2  Rio de Janeiro    Brazil  130.21   57.22  98.51   9.92  0.12  179.31   \n",
            "3          Mumbai     India  119.70  130.52  10.96  33.03  7.74   38.65   \n",
            "4           Paris    France   55.20   36.62  76.85  21.85  2.00   67.09   \n",
            "\n",
            "   Temperature  Humidity  Wind Speed  \n",
            "0        17.67     59.35       13.76  \n",
            "1         3.46     67.51        6.36  \n",
            "2        25.29     29.30       12.87  \n",
            "3        23.15     99.97        7.71  \n",
            "4        16.02     90.28       14.16  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate MAE and RMSE\n",
        "def evaluate_model(actual, predicted):\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
        "    return mae, rmse"
      ],
      "metadata": {
        "id": "xgtqBqKDM68v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_models_for_city(city_data, city_name):\n",
        "    print(f\"\\nTraining models for city: {city_name}\")\n",
        "    series = city_data[target_col].astype(float).reset_index(drop=True)\n",
        "\n",
        "    # Original 'Date' column is unusable)\n",
        "    city_data = city_data.copy()\n",
        "    city_data[\"ds\"] = pd.date_range(start=\"2020-01-01\", periods=len(series), freq=\"D\")\n",
        "    city_data[\"y\"] = series\n",
        "\n",
        "    # Train/test split\n",
        "    split = int(len(series) * 0.8)\n",
        "    train = series[:split]\n",
        "    test = series[split:]\n",
        "    actual = test.values\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # ARIMA\n",
        "    try:\n",
        "        arima_model = ARIMA(train, order=(2, 1, 2))\n",
        "        arima_fit = arima_model.fit()\n",
        "        pred_arima = arima_fit.forecast(steps=len(test))\n",
        "        results[\"ARIMA\"] = evaluate_model(actual, pred_arima)\n",
        "    except Exception as e:\n",
        "        print(\"ARIMA failed:\", e)\n",
        "        results[\"ARIMA\"] = (np.nan, np.nan)\n",
        "\n",
        "    # Prophet\n",
        "    try:\n",
        "        train_p = city_data.iloc[:split][[\"ds\", \"y\"]]\n",
        "        test_p = city_data.iloc[split:][[\"ds\", \"y\"]]\n",
        "\n",
        "        prophet_model = Prophet()\n",
        "        prophet_model.fit(train_p)\n",
        "\n",
        "        future = prophet_model.make_future_dataframe(periods=len(test_p), freq=\"D\")\n",
        "        forecast = prophet_model.predict(future)\n",
        "        pred_prophet = forecast[\"yhat\"].iloc[-len(test_p):].values\n",
        "        results[\"Prophet\"] = evaluate_model(actual, pred_prophet)\n",
        "    except Exception as e:\n",
        "        print(\"Prophet failed:\", e)\n",
        "        results[\"Prophet\"] = (np.nan, np.nan)\n",
        "\n",
        "    # LSTM\n",
        "    try:\n",
        "        scaler = MinMaxScaler()\n",
        "        scaled = scaler.fit_transform(series.values.reshape(-1, 1))\n",
        "\n",
        "        def create_dataset(data, lag=5):\n",
        "            X, y = [], []\n",
        "            for i in range(lag, len(data)):\n",
        "                X.append(data[i - lag:i, 0])\n",
        "                y.append(data[i, 0])\n",
        "            return np.array(X), np.array(y)\n",
        "\n",
        "        X, y = create_dataset(scaled)\n",
        "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "        split_lstm = int(len(X) * 0.8)\n",
        "        X_train, X_test = X[:split_lstm], X[split_lstm:]\n",
        "        y_train, y_test = y[:split_lstm], y[split_lstm:]\n",
        "\n",
        "        lstm_model = Sequential([\n",
        "            LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "            Dense(1)\n",
        "        ])\n",
        "        lstm_model.compile(optimizer='adam', loss='mse')\n",
        "        lstm_model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0)\n",
        "\n",
        "        y_pred = lstm_model.predict(X_test)\n",
        "        y_pred_inv = scaler.inverse_transform(y_pred)\n",
        "        y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "        results[\"LSTM\"] = evaluate_model(y_test_inv.flatten(), y_pred_inv.flatten())\n",
        "    except Exception as e:\n",
        "        print(\"LSTM failed:\", e)\n",
        "        results[\"LSTM\"] = (np.nan, np.nan)\n",
        "\n",
        "    # XGBoost\n",
        "    try:\n",
        "        df_lag = pd.DataFrame(series)\n",
        "        for lag in range(1, 4):\n",
        "            df_lag[f\"lag_{lag}\"] = df_lag[target_col].shift(lag)\n",
        "        df_lag.dropna(inplace=True)\n",
        "\n",
        "        X = df_lag[[f\"lag_{i}\" for i in range(1, 4)]]\n",
        "        y = df_lag[target_col]\n",
        "        split_xgb = int(len(X) * 0.8)\n",
        "        X_train, X_test = X.iloc[:split_xgb], X.iloc[split_xgb:]\n",
        "        y_train, y_test = y.iloc[:split_xgb], y.iloc[split_xgb:]\n",
        "\n",
        "        xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=150)\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "        pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "        results[\"XGBoost\"] = evaluate_model(y_test, pred_xgb)\n",
        "    except Exception as e:\n",
        "        print(\"XGBoost failed:\", e)\n",
        "        results[\"XGBoost\"] = (np.nan, np.nan)\n",
        "\n",
        "    # Compare results\n",
        "    result_df = pd.DataFrame(results, index=[\"MAE\", \"RMSE\"]).T\n",
        "    print(\"\\nModel Performance Summary:\")\n",
        "    print(result_df)\n",
        "\n",
        "    # Pick best model (lowest RMSE)\n",
        "    best_model = min(results, key=lambda k: results[k][1] if not np.isnan(results[k][1]) else np.inf)\n",
        "    print(f\"Best model for {city_name}: {best_model}\")\n",
        "\n",
        "    # Save best model\n",
        "    if best_model == \"ARIMA\":\n",
        "        joblib.dump(arima_fit, f\"{city_name}_best_model.pkl\")\n",
        "    elif best_model == \"Prophet\":\n",
        "        pickle.dump(prophet_model, open(f\"{city_name}_best_model.pkl\", \"wb\"))\n",
        "    elif best_model == \"LSTM\":\n",
        "        lstm_model.save(f\"{city_name}_best_model.h5\")\n",
        "    elif best_model == \"XGBoost\":\n",
        "        joblib.dump(xgb_model, f\"{city_name}_best_model.pkl\")\n",
        "\n",
        "    print(f\"Saved best model for {city_name}\\n\")\n",
        "\n",
        "    return result_df\n"
      ],
      "metadata": {
        "id": "ig8oqwZvOd_h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cities_to_run = [\"Mumbai\", \"Paris\", \"Tokyo\"]\n",
        "\n",
        "for city in cities_to_run:\n",
        "    city_data = data[data[\"City\"] == city]\n",
        "    if not city_data.empty:\n",
        "        train_models_for_city(city_data, city)\n",
        "    else:\n",
        "        print(f\"No data found for {city}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nNErF-TP5Ew",
        "outputId": "70b239bf-8233-4f04-9c23-ed607ad8b419"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training models for city: Mumbai\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
            "  warn('Non-invertible starting MA parameters found.'\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 18.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpucjx0wa6/wuas5gvh.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpucjx0wa6/pf10pnzd.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=85159', 'data', 'file=/tmp/tmpucjx0wa6/wuas5gvh.json', 'init=/tmp/tmpucjx0wa6/pf10pnzd.json', 'output', 'file=/tmp/tmpucjx0wa6/prophet_modelhi5algxy/prophet_model-20251023132611.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:26:11 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:26:11 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "\n",
            "Model Performance Summary:\n",
            "                MAE        RMSE\n",
            "ARIMA     46.573521   50.333225\n",
            "Prophet  835.064751  838.795288\n",
            "LSTM      46.941708   50.944909\n",
            "XGBoost   47.601177   55.346927\n",
            "Best model for Mumbai: ARIMA\n",
            "Saved best model for Mumbai\n",
            "\n",
            "\n",
            "Training models for city: Paris\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
            "  warn('Non-stationary starting autoregressive parameters'\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
            "  warn('Non-invertible starting MA parameters found.'\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 17.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpucjx0wa6/7yhobnwb.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpucjx0wa6/i_d4xln8.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=86785', 'data', 'file=/tmp/tmpucjx0wa6/7yhobnwb.json', 'init=/tmp/tmpucjx0wa6/i_d4xln8.json', 'output', 'file=/tmp/tmpucjx0wa6/prophet_modellp252fwy/prophet_model-20251023132616.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:26:16 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:26:16 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Summary:\n",
            "                MAE        RMSE\n",
            "ARIMA     32.773664   37.450219\n",
            "Prophet  536.390687  538.720398\n",
            "LSTM      31.914418   36.770481\n",
            "XGBoost   37.904328   46.733681\n",
            "Best model for Paris: LSTM\n",
            "Saved best model for Paris\n",
            "\n",
            "\n",
            "Training models for city: Tokyo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
            "  warn('Non-stationary starting autoregressive parameters'\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
            "  warn('Non-invertible starting MA parameters found.'\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 10.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpucjx0wa6/e5e6fhse.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpucjx0wa6/pppfpqzk.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=98192', 'data', 'file=/tmp/tmpucjx0wa6/e5e6fhse.json', 'init=/tmp/tmpucjx0wa6/pppfpqzk.json', 'output', 'file=/tmp/tmpucjx0wa6/prophet_modelhz099g1w/prophet_model-20251023132621.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:26:21 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:26:21 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\n",
            "Model Performance Summary:\n",
            "                 MAE         RMSE\n",
            "ARIMA      33.058993    38.363569\n",
            "Prophet  1061.630974  1064.432029\n",
            "LSTM       32.242974    38.386472\n",
            "XGBoost    35.204938    42.584474\n",
            "Best model for Tokyo: ARIMA\n",
            "Saved best model for Tokyo\n",
            "\n"
          ]
        }
      ]
    }
  ]
}